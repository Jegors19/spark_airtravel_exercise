{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Init pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "# Init sparksql -- Only used to format the output nicely!\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "rows = sc.textFile(\"/air_transit_2007.csv\")\n",
    "data = rows.map(lambda line: line.split(\",\"))\n",
    "# data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|Sched. Departure|Destination|\n",
      "+----------------+-----------+\n",
      "|            1455|        CLE|\n",
      "|            1840|        CLE|\n",
      "|             659|        CLE|\n",
      "|            1750|        EWR|\n",
      "|             630|        EWR|\n",
      "|            1650|        EWR|\n",
      "|            1255|        EWR|\n",
      "|            1025|        EWR|\n",
      "|            1034|        IAD|\n",
      "|            1607|        IAD|\n",
      "+----------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_results = data.filter(lambda r: (r[16]=='ROC'and r[1]=='3' and r[2]=='12')) \\\n",
    "    .map(lambda r: (r[5] , r[17])) \\\n",
    "    .collect()\n",
    "\n",
    "#format nicely!\n",
    "sqlContext.createDataFrame(sample_results, ['Sched. Departure', 'Destination']).show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "I have removed all the rows that NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number:  7275289\n"
     ]
    }
   ],
   "source": [
    "# Response...\n",
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "total_records = data_removed_na.count()\n",
    "print(\"Total number: \", total_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "I have removed all the rows that NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|Month|Total Flights|\n",
      "+-----+-------------+\n",
      "|    1|       604582|\n",
      "|    2|       538878|\n",
      "|    3|       621057|\n",
      "|    4|       602317|\n",
      "|    5|       623326|\n",
      "|    6|       609838|\n",
      "|    7|       632904|\n",
      "|    8|       638883|\n",
      "|    9|       592718|\n",
      "|   10|       621665|\n",
      "|   11|       597989|\n",
      "|   12|       591131|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "\n",
    "header = data_removed_na.first()\n",
    "data_no_header_no_na = data_removed_na.filter(lambda row: row != header)\n",
    "\n",
    "\n",
    "# Assuming the month is the second column in your data\n",
    "flights_per_month = data_no_header_no_na.map(lambda r: (int(r[1]), 1)) \\\n",
    "                        .reduceByKey(lambda a, b: a + b) \\\n",
    "                        .sortByKey(True).collect()\n",
    "# flights_per_month\n",
    "\n",
    "sqlContext.createDataFrame(flights_per_month, ['Month', 'Total Flights']).show(n=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "##### Find the plane with the highest number of flights. Each plane has a unique TailNum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|Tail Number|Total Flights|\n",
      "+-----------+-------------+\n",
      "|     N655BR|         4457|\n",
      "|     N479HA|         4359|\n",
      "|     N651BR|         4324|\n",
      "|     N478HA|         4316|\n",
      "|     N654BR|         4251|\n",
      "|     N480HA|         4225|\n",
      "|     N485HA|         4203|\n",
      "|     N484HA|         4126|\n",
      "|     N693BR|         4088|\n",
      "|     N481HA|         4045|\n",
      "|     N487HA|         4038|\n",
      "|     N477HA|         3958|\n",
      "|     N810AL|         3938|\n",
      "|     N837AL|         3881|\n",
      "|     N475HA|         3854|\n",
      "|     N486HA|         3820|\n",
      "|     N476HA|         3685|\n",
      "|     N836AL|         3679|\n",
      "|     N808AL|         3676|\n",
      "|     N824AL|         3671|\n",
      "|     N646BR|         3502|\n",
      "|     N828AL|         3493|\n",
      "|     N295SW|         3462|\n",
      "|     N226SW|         3462|\n",
      "|     N835AL|         3440|\n",
      "+-----------+-------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "\n",
    "header = data_removed_na.first()\n",
    "data_no_header_no_na = data_removed_na.filter(lambda row: row != header)\n",
    "\n",
    "tailNum_data = data_no_header_no_na.map(lambda r: (r[10], 1)) \n",
    "\n",
    "# Reduce by key (TailNum here) to get the counts\n",
    "tailNum_counts = tailNum_data.reduceByKey(lambda a, b: a+b)\n",
    "top_planes = tailNum_counts.takeOrdered(50, key = lambda x: -x[1])\n",
    "\n",
    "sqlContext.createDataFrame(top_planes, ['Tail Number', 'Total Flights']).show(n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 \n",
    "Removed all NAs and used isdigit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|Tail Number|Flight Time|\n",
      "+-----------+-----------+\n",
      "|     N556AS|     532213|\n",
      "|     N557UA|     259376|\n",
      "|     N597UA|     254760|\n",
      "|     N636JB|     254357|\n",
      "|     N637JB|     253562|\n",
      "|     N590NW|     253079|\n",
      "|     N607JB|     252862|\n",
      "|     N590UA|     252847|\n",
      "|     N505UA|     252382|\n",
      "|     N554UA|     252378|\n",
      "|     N558AS|     251992|\n",
      "|     N212UA|     251816|\n",
      "|     N598UA|     250612|\n",
      "|     N624JB|     250327|\n",
      "|     N646JB|     249865|\n",
      "|     N625JB|     249089|\n",
      "|     N543UA|     248784|\n",
      "|     N599JB|     248747|\n",
      "|     N565AS|     248648|\n",
      "|     N640JB|     248571|\n",
      "|     N618JB|     248465|\n",
      "|     N666UA|     248352|\n",
      "|     N595UA|     248135|\n",
      "|     N639JB|     247980|\n",
      "|     N649JB|     247807|\n",
      "+-----------+-----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove rows containing 'NA'\n",
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "\n",
    "# Remove the header\n",
    "header = data_removed_na.first()\n",
    "data_no_header_no_na = data_removed_na.filter(lambda row: row != header)\n",
    "\n",
    "# Filter out rows with non-numeric values in the flight time and map the results\n",
    "flightTime_data = data_no_header_no_na.filter(\n",
    "    lambda r: all(i.replace('.', '', 1).isdigit() for i in r[13].split())  # Check if the value is numeric\n",
    ").map(\n",
    "    lambda r: (r[10], int(r[13]))  # Map the results to tuples\n",
    ")\n",
    "\n",
    "# Sum flight times per tail number\n",
    "flightTime_totals = flightTime_data.reduceByKey(lambda a, b: a+b)\n",
    "\n",
    "# Get the top 100 planes with the most total flight time\n",
    "top_flightTimes = flightTime_totals.takeOrdered(100, key=lambda x: -x[1])\n",
    "\n",
    "# Display the results\n",
    "sqlContext.createDataFrame(top_flightTimes, ['Tail Number', 'Flight Time']).show(n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5\n",
    "Removed all NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|Month|Airport|Flights|\n",
      "+-----+-------+-------+\n",
      "|    1|    ATL|  62801|\n",
      "|    2|    ATL|  57583|\n",
      "|    3|    ATL|  66647|\n",
      "|    4|    ATL|  64838|\n",
      "|    5|    ATL|  67819|\n",
      "|    6|    ATL|  69936|\n",
      "|    7|    ATL|  72121|\n",
      "|    8|    ATL|  72453|\n",
      "|    9|    ATL|  67598|\n",
      "|   10|    ATL|  73016|\n",
      "|   11|    ATL|  68793|\n",
      "|   12|    ATL|  67502|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "\n",
    "header = data_removed_na.first()\n",
    "data_no_header_no_na = data_removed_na.filter(lambda row: row != header)\n",
    "\n",
    "\n",
    "# Assuming 'Month' is the 2nd column, 'Origin' is the 17th column, and 'Dest' is the 18th column\n",
    "departures = data_no_header_no_na.map(lambda r: ((r[1], r[16]), 1))\n",
    "arrivals = data_no_header_no_na.map(lambda r: ((r[1], r[17]), 1))\n",
    "\n",
    "# Merge the two datasets and reduce\n",
    "all_flights = departures.union(arrivals)\n",
    "\n",
    "\n",
    "total_flights = all_flights.reduceByKey(add)\n",
    "\n",
    "\n",
    "# Reshape ((Month, Airport), Count) to (Month, (Airport, Count)) and get the busiest airport for each month\n",
    "busiest_airports = total_flights.map(lambda x: (x[0][0],(x[0][1], x[1]))).reduceByKey(lambda a, b: a if a[1] > b[1] else b)\n",
    "\n",
    "\n",
    "\n",
    "results = busiest_airports.map(lambda x: (int(x[0]), x[1][0], x[1][1])).sortBy(lambda x: x[0]).collect()\n",
    "\n",
    "sqlContext.createDataFrame(results, ['Month', 'Airport', 'Flights']).show(n=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6\n",
    "Find the airline with highest average delay of each type in March 2007. Note: do not write \n",
    "separate code for each error type. You should compute a single RDD where each row contains\n",
    "the delay type, the airline that is worst regarding that delay type, and its average delay of tha \n",
    "type in minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay Type: WeatherDelay, Worst Airline: OH, Average Delay: 3.633 minutes\n",
      "Delay Type: NASDelay, Worst Airline: B6, Average Delay: 7.662 minutes\n",
      "Delay Type: LateAircraftDelay, Worst Airline: B6, Average Delay: 7.861 minutes\n",
      "Delay Type: ArrDelay, Worst Airline: EV, Average Delay: 17.196 minutes\n",
      "Delay Type: CarrierDelay, Worst Airline: EV, Average Delay: 10.239 minutes\n",
      "Delay Type: SecurityDelay, Worst Airline: AS, Average Delay: 0.086 minutes\n",
      "Delay Type: DepDelay, Worst Airline: EV, Average Delay: 20.272 minutes\n"
     ]
    }
   ],
   "source": [
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "\n",
    "header = data_removed_na.first()\n",
    "data_no_header_no_na = data_removed_na.filter(lambda row: row != header)\n",
    "\n",
    "# Then, create a new RDD where each row contains 'DelayType', 'Delay', 'UniqueCarrier' and 'Month'\n",
    "delay_types = ['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay','ArrDelay', 'DepDelay']\n",
    "delay_indices = [24, 25, 26, 27, 28, 14, 15]\n",
    "\n",
    "delay_data = data_no_header_no_na.flatMap(lambda r: [((delay_type, r[8]), float(r[delay_index])) for delay_type, delay_index in zip(delay_types, delay_indices) if r[delay_index] != 'NA'])\n",
    "\n",
    "# Compute averages for each 'DelayType' and 'UniqueCarrier'\n",
    "delay_averages = delay_data.mapValues(lambda v: (v, 1)).reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1])).mapValues(lambda v: v[0]/v[1])\n",
    "\n",
    "# Find the airline with the highest average delay for each type\n",
    "worst_airlines = delay_averages.map(lambda x: (x[0][0], (x[0][1], x[1]))).reduceByKey(lambda a, b: a if a[1] > b[1] else b)\n",
    "\n",
    "# Print the results\n",
    "results = worst_airlines.collect()\n",
    "for result in results:\n",
    "    print(f'Delay Type: {result[0]}, Worst Airline: {result[1][0]}, Average Delay: {round(result[1][1], 3)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------------+\n",
      "|       Delay Type|Airline|Average Delay|\n",
      "+-----------------+-------+-------------+\n",
      "|     WeatherDelay|     OH|         3.63|\n",
      "|         NASDelay|     B6|         7.66|\n",
      "|LateAircraftDelay|     B6|         7.86|\n",
      "|         ArrDelay|     EV|         17.2|\n",
      "|     CarrierDelay|     EV|        10.24|\n",
      "|    SecurityDelay|     AS|         0.09|\n",
      "|         DepDelay|     EV|        20.27|\n",
      "+-----------------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define the DataFrame schema as a list of column names and types\n",
    "schema = [\"Delay Type\", \"Airline\", \"Average Delay\"]\n",
    "flat_results = [(result[0], result[1][0], round(result[1][1], 2)) for result in results]\n",
    "\n",
    "# Convert the results into DataFrame\n",
    "df = spark.createDataFrame(flat_results, schema)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7\n",
    "Compute median, mean, and mode of columns 12-16, 19-21 and 25-29 for the flights in the third \n",
    "week of 2007. Exclude the non-numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1149/3445692407.py:16: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return median(column_data), mean(column_data), int(stats.mode(column_data)[0][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+------+----+\n",
      "|      column_name|  mean|median|mode|\n",
      "+-----------------+------+------+----+\n",
      "|ActualElapsedTime|128.31| 110.0|  80|\n",
      "|   CRSElapsedTime|127.31| 109.0|  75|\n",
      "|          AirTime|103.11|  84.0|  59|\n",
      "|         ArrDelay| 15.97|   2.0|  -5|\n",
      "|         DepDelay| 14.97|   0.0|   0|\n",
      "|         Distance| 714.0| 557.0| 337|\n",
      "|           TaxiIn|  7.07|   6.0|   4|\n",
      "|          TaxiOut| 18.13|  14.0|  10|\n",
      "|     CarrierDelay|  4.23|   0.0|   0|\n",
      "|     WeatherDelay|  1.73|   0.0|   0|\n",
      "|         NASDelay|  5.69|   0.0|   0|\n",
      "|    SecurityDelay|  0.01|   0.0|   0|\n",
      "|LateAircraftDelay|  7.37|   0.0|   0|\n",
      "+-----------------+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col\n",
    "from statistics import mean, median\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "data_removed_na = data.filter(lambda row: 'NA' not in row)\n",
    "\n",
    "header = data_removed_na.first()\n",
    "data_no_header_no_na = data_removed_na.filter(lambda row: row != header)\n",
    "\n",
    "\n",
    "# Assume that SparkContext is available as sc\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# Filter data for the third week of 2007\n",
    "data_3rd_week_2007 = data_no_header_no_na.filter(lambda row: row[0] == '2007' and int(row[1]) == 1 and int(row[2]) >= 15 and int(row[2]) <= 21)\n",
    "\n",
    "# Define function to compute median, mean and mode\n",
    "def compute_statistics(column_index):\n",
    "    column_data = data_3rd_week_2007.map(lambda row: int(row[column_index])).filter(lambda x: x is not None).collect()\n",
    "    return median(column_data), mean(column_data), int(stats.mode(column_data)[0][0])\n",
    "\n",
    "# Define columns to compute statistics\n",
    "columns = [11, 12, 13, 14, 15, 18, 19, 20, 24, 25, 26, 27, 28]\n",
    "\n",
    "## BETTER DESIGN USING PYTHON\n",
    "column_names = [\n",
    "    'ActualElapsedTime',\n",
    "    'CRSElapsedTime',\n",
    "    'AirTime',\n",
    "    'ArrDelay',\n",
    "    'DepDelay',\n",
    "    'Distance',\n",
    "    'TaxiIn',\n",
    "    'TaxiOut',\n",
    "    'CarrierDelay',\n",
    "    'WeatherDelay',\n",
    "    'NASDelay',\n",
    "    'SecurityDelay',\n",
    "    'LateAircraftDelay'\n",
    "]\n",
    "\n",
    "# Compute statistics and store them in a list of Rows\n",
    "results = []\n",
    "for column, column_name in zip(columns, column_names):\n",
    "    median_val, mean_val, mode_val = compute_statistics(column)\n",
    "    results.append(Row(column_name=column_name,mean=round(mean_val,2), median=round(median_val,0), mode=mode_val))\n",
    "\n",
    "# Convert list of Rows to DataFrame\n",
    "df = spark.createDataFrame(results)\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8 \n",
    "#### Assumption\n",
    "\n",
    "I have calculated the possible number of combinations with all the time constraints and the same carrier. Added the constraint of the same day e.g. depart 23:50 will arrive the same day at 5am.\n",
    "This question was slightly confusing and the exact definition of flights was not indicated. Therefore, I have used combinations of possible flights using the same airline. \n",
    "\n",
    "\n",
    "This specific instance is using the cartesian command, which will parse all possible combinations of flights that will give us a definitive answer. However, it might take some time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = sc.textFile(\"/air_transit_2007.csv\")\n",
    "data = rows.map(lambda line: line.split(\",\"))\n",
    "\n",
    "header = data.first() #extract header\n",
    "no_header_data = data.filter(lambda row : row != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|Carrier|Combinations|\n",
      "+-------+------------+\n",
      "|     US|         156|\n",
      "|     WN|          28|\n",
      "|     UA|          97|\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Index for readability\n",
    "month_index = 1\n",
    "year_index = 0\n",
    "day_index = 2\n",
    "origin_index = 16\n",
    "dest_index = 17\n",
    "crsdeptime_index = 5\n",
    "crsarrtime_index = 7 \n",
    "carrier_index = 8\n",
    "\n",
    "data_q8 = no_header_data.filter(lambda line: line[month_index] == '2' and line[year_index] == '2007')\n",
    "\n",
    "# Filter for the flights from PHL to LAX after 05:59\n",
    "outbound_flights = data_q8.filter(lambda line: line[origin_index] == 'PHL' and line[dest_index] == 'LAX' and int(line[crsdeptime_index]) > 559)\n",
    "\n",
    "# Filter for the flights from LAX to PHL before 23:00\n",
    "inbound_flights = data_q8.filter(lambda line: line[origin_index] == 'LAX' and line[dest_index] == 'PHL' and int(line[crsarrtime_index]) < 2300)\n",
    "\n",
    "# Ensure there is at least 3 hours and 1 minute (181 minutes) layover time and it is the same day\n",
    "flights_combination = outbound_flights.cartesian(inbound_flights).filter(\n",
    "    lambda x: (int(x[0][crsarrtime_index]) - int(x[1][crsdeptime_index]) <= 181) and\n",
    "              (x[1][day_index] == x[0][day_index])\n",
    ")\n",
    "\n",
    "#Grab the proof - next cells \n",
    "first_10_rows = flights_combination.take(10)\n",
    "df = pd.DataFrame(first_10_rows)\n",
    "\n",
    "# Filter for the same carrier combinations\n",
    "flights_combination_same_carrier = flights_combination.filter(lambda x: x[0][carrier_index] == x[1][carrier_index])\n",
    "\n",
    "# Count the combinations for each carrier - reduce\n",
    "carrier_combinations = flights_combination_same_carrier.map(lambda x: (x[0][8], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Collect the results\n",
    "results = carrier_combinations.collect()\n",
    "#Visual\n",
    "sqlContext.createDataFrame(results, ['Carrier', 'Combinations']).show(n=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The highest possible combinations only using the same carrier in a month is US with 156 possible ones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the proof table, where I have compared the actual numbers to verify the correctness. 0 is outbound, 1 is inbound\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9\n",
    "\n",
    "In this question I have used all the data, since none of the NA values appeared in our timetable.\n",
    "I have added a different and more readible style for the table, as well as added the Status column, which uses simple if statements.on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = sc.textFile(\"/air_transit_2007.csv\")\n",
    "data = rows.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤════════════╤═══════════╤═══════╤════════╤═══════════════╕\n",
      "│    │ Schedule   │ Status    │ Air   │ Dest   │ Actual Time   │\n",
      "╞════╪════════════╪═══════════╪═══════╪════════╪═══════════════╡\n",
      "│  0 │ 12:00      │ Departed  │ WN    │ OAK    │ 12:56         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  1 │ 12:00      │ Departed  │ AA    │ JFK    │ 11:59         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  2 │ 12:00      │ Departed  │ CO    │ IAH    │ 12:13         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  3 │ 12:05      │ Departed  │ AA    │ MIA    │ 12:06         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  4 │ 12:11      │ Departed  │ NW    │ MSP    │ 12:54         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  5 │ 12:14      │ Departed  │ OO    │ SAN    │ 12:17         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  6 │ 12:15      │ Departed  │ WN    │ SJC    │ 12:13         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  7 │ 12:15      │ Departed  │ DL    │ ATL    │ 12:17         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  8 │ 12:20      │ Departed  │ FL    │ ATL    │ 12:16         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│  9 │ 12:20      │ Departed  │ MQ    │ MRY    │ 12:15         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 10 │ 12:24      │ Departed  │ OO    │ SJC    │ 12:24         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 11 │ 12:24      │ Departed  │ UA    │ SFO    │ 12:19         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 12 │ 12:25      │ Departed  │ OO    │ OAK    │ 12:26         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 13 │ 12:29      │ Departed  │ OO    │ SAN    │ 12:29         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 14 │ 12:29      │ Departed  │ UA    │ DEN    │ 12:50         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 15 │ 12:30      │ Departed  │ WN    │ LAS    │ 12:52         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 16 │ 12:30      │ Departed  │ NW    │ DTW    │ 12:43         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 17 │ 12:31      │ Departed  │ US    │ LAS    │ 12:45         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 18 │ 12:35      │ Departed  │ WN    │ BWI    │ 12:47         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 19 │ 12:35      │ Departed  │ WN    │ MDW    │ 12:55         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 20 │ 12:35      │ Boarding  │ AS    │ SEA    │ 13:15         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 21 │ 12:35      │ Departed  │ CO    │ IAH    │ 12:28         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 22 │ 12:38      │ Departed  │ OO    │ SMX    │ 12:41         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 23 │ 12:40      │ Departed  │ WN    │ ELP    │ 12:39         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 24 │ 12:40      │ Departed  │ UA    │ PDX    │ 12:36         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 25 │ 12:40      │ Departed  │ UA    │ LAS    │ 12:46         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 26 │ 12:40      │ Departed  │ US    │ PHL    │ 12:52         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 27 │ 12:40      │ Departed  │ AA    │ DEN    │ 12:54         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 28 │ 12:44      │ Departed  │ OO    │ MRY    │ 12:42         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 29 │ 12:44      │ Departed  │ OO    │ SBA    │ 12:47         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 30 │ 12:45      │ Boarding  │ WN    │ MCI    │ 13:17         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 31 │ 12:45      │ Departed  │ UA    │ IAD    │ 12:53         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 32 │ 12:45      │ Departed  │ US    │ PHX    │ 12:46         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 33 │ 12:45      │ Departed  │ US    │ PHX    │ 12:48         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 34 │ 12:45      │ Departed  │ MQ    │ SBP    │ 12:44         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 35 │ 12:45      │ Departed  │ MQ    │ SAN    │ 12:45         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 36 │ 12:45      │ Departed  │ DL    │ CVG    │ 12:42         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 37 │ 12:46      │ Departed  │ AS    │ DCA    │ 12:36         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 38 │ 12:50      │ Boarding  │ OO    │ PHX    │ 13:13         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 39 │ 12:50      │ Boarding  │ NW    │ MEM    │ 13:15         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 40 │ 12:50      │ Departed  │ AA    │ BOS    │ 13:00         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 41 │ 12:50      │ Boarding  │ AA    │ DFW    │ 13:26         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 42 │ 12:55      │ Departed  │ WN    │ SJC    │ 12:56         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 43 │ 12:55      │ Departed  │ UA    │ BOS    │ 12:53         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 44 │ 12:55      │ Closed    │ UA    │ SFO    │ 13:01         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 45 │ 12:55      │ Check-In  │ MQ    │ FAT    │ 13:45         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 46 │ 12:55      │ Check-In  │ AA    │ ORD    │ 16:21         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 47 │ 12:55      │ Closed    │ AA    │ SFO    │ 13:01         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 48 │ 12:59      │ Boarding  │ OO    │ SAN    │ 13:30         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 49 │ 12:59      │ LAST CALL │ DL    │ JFK    │ 13:06         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 50 │ 13:00      │ LAST CALL │ WN    │ OAK    │ 13:07         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 51 │ 13:00      │ Boarding  │ OO    │ RNO    │ 13:14         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 52 │ 13:00      │ LAST CALL │ UA    │ HNL    │ 13:04         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 53 │ 13:00      │ Closed    │ UA    │ ORD    │ 13:01         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 54 │ 13:00      │ Check-In  │ CO    │ EWR    │ 13:39         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 55 │ 13:05      │ Boarding  │ WN    │ ABQ    │ 13:21         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 56 │ 13:10      │ Check-In  │ WN    │ PHX    │ 13:51         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 57 │ 13:10      │ LAST CALL │ UA    │ DFW    │ 13:10         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 58 │ 13:10      │ LAST CALL │ US    │ CLT    │ 13:04         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 59 │ 13:15      │ Check-In  │ OO    │ ONT    │ 13:46         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 60 │ 13:15      │ Boarding  │ UA    │ JFK    │ 13:28         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 61 │ 13:15      │ Check-In  │ MQ    │ SBA    │ 13:42         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 62 │ 13:19      │ Boarding  │ OO    │ SMF    │ 13:20         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 63 │ 13:20      │ Check-In  │ UA    │ LIH    │ 13:40         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 64 │ 13:20      │ Check-In  │ AA    │ JFK    │ 13:42         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 65 │ 13:25      │ Check-In  │ MQ    │ LAS    │ 13:38         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 66 │ 13:25      │ Boarding  │ AA    │ MIA    │ 13:24         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 67 │ 13:28      │ Boarding  │ OO    │ SBP    │ 13:28         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 68 │ 13:30      │ Boarding  │ MQ    │ SJC    │ 13:28         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 69 │ 13:34      │ Check-In  │ OO    │ ABQ    │ 13:44         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 70 │ 13:35      │ Check-In  │ WN    │ PHL    │ 13:42         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 71 │ 13:35      │ Check-In  │ WN    │ SMF    │ 13:50         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 72 │ 13:35      │ Check-In  │ DL    │ SLC    │ 13:43         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 73 │ 13:37      │ Check-In  │ OO    │ SGU    │ 13:53         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 74 │ 13:40      │ Check-In  │ WN    │ PHX    │ 14:06         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 75 │ 13:40      │ Check-In  │ F9    │ SFO    │ 13:47         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 76 │ 13:40      │ Check-In  │ MQ    │ SAN    │ 13:37         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 77 │ 13:40      │ Check-In  │ DL    │ ATL    │ 14:24         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 78 │ 13:43      │ Check-In  │ OO    │ COS    │ 13:53         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 79 │ 13:45      │ Check-In  │ OO    │ CLD    │ 13:44         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 80 │ 13:45      │ Check-In  │ OO    │ BFL    │ 13:55         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 81 │ 13:45      │ Check-In  │ AA    │ AUS    │ 13:43         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 82 │ 13:45      │ Check-In  │ AA    │ DFW    │ 13:42         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 83 │ 13:51      │ Check-In  │ UA    │ SFO    │ 13:54         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 84 │ 13:55      │ Check-In  │ WN    │ RNO    │ 14:03         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 85 │ 13:56      │ Check-In  │ UA    │ PHL    │ 14:22         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 86 │ 14:00      │ Check-In  │ WN    │ OAK    │ 14:14         │\n",
      "├────┼────────────┼───────────┼───────┼────────┼───────────────┤\n",
      "│ 87 │ 14:00      │ Check-In  │ UA    │ ORD    │ 14:48         │\n",
      "╘════╧════════════╧═══════════╧═══════╧════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Helper function to format time\n",
    "def format_time(time_str):\n",
    "    if time_str != '':\n",
    "        formatted = time_str.zfill(4)\n",
    "        return formatted[:2] + ':' + formatted[2:]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "month_index = 1\n",
    "day_index = 2\n",
    "year_index = 0\n",
    "origin_index = 16\n",
    "deptime_index = 4\n",
    "crsdeptime_index = 5\n",
    "carrier_index = 8\n",
    "dest_index = 17\n",
    "        \n",
    "\n",
    "header = data.first() #extract header\n",
    "no_header_data = data.filter(lambda row : row != header)\n",
    "\n",
    "# Filter data\n",
    "la_flights = no_header_data.filter(lambda row: (row[origin_index] == 'LAX' and \n",
    "                                                row[year_index] == '2007' and \n",
    "                                                row[month_index] == '1' and \n",
    "                                                row[day_index] == '12' and \n",
    "                                                int(row[crsdeptime_index]) >= 1200 and \n",
    "                                                int(row[crsdeptime_index]) <= 1400))\n",
    "\n",
    "\n",
    "\n",
    "# Sort by scheduled departure time\n",
    "sorted_la_flights = la_flights.sortBy(lambda row: row[crsdeptime_index])\n",
    "\n",
    "selected_la_flights = sorted_la_flights.map(lambda row: [format_time(row[crsdeptime_index]), \n",
    "                                                         'Departed' if int(row[deptime_index]) <= 1300 else ('Closed' if int(row[deptime_index]) <= 1303 else(\n",
    "                                                         'LAST CALL' if int(row[deptime_index]) <= 1310 else ('Boarding' if int(row[deptime_index]) <= 1330 else 'Check-In'))), \n",
    "                                                         row[carrier_index], \n",
    "                                                         row[dest_index],\n",
    "                                                         format_time(row[deptime_index])])\n",
    "\n",
    "# sqlContext.createDataFrame(selected_la_flights, ['Scheduled DepTime', 'Status', 'Airline Code', 'Destination', 'Actual Time']).show(n=500)\n",
    "## BETTER FORMATTING \n",
    "table = selected_la_flights.toDF(['Scheduled DepTime', 'Status', 'Airline Code', 'Destination', 'Actual Time'])\n",
    "table = table.limit(100)  # limited at 100 as asked \n",
    "\n",
    "# Convert the DataFrame to a pandas DataFrame\n",
    "pandas_df = table.toPandas()\n",
    "\n",
    "# Define the headers\n",
    "headers = ['Schedule', 'Status', 'Air', 'Dest', 'Actual Time']\n",
    "\n",
    "# Apply ASCII formatting to the table\n",
    "formatted_table = tabulate(pandas_df, headers, tablefmt='fancy_grid')\n",
    "\n",
    "print(formatted_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you and have a good day! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
